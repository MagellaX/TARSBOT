---
title: "Helm Deployment"
description: "Deploy TARS on Kubernetes using Helm charts"
---

# Deploy TARS on Kubernetes with Helm

Helm provides a simple way to deploy TARS on Kubernetes clusters.

## Prerequisites

- Kubernetes cluster (1.19+)
- Helm 3.x installed
- kubectl configured
- 8GB+ available memory in cluster

## Quick Start

<Steps>
  <Step title="Clone Repository">
    ```bash
    git clone https://github.com/MagellaX/TARSBOT.git
    cd TARSBOT
    ```
  </Step>
  
  <Step title="Configure API Keys">
    Create a `values.yaml` file with at least one API key:
    
    ```yaml
    tars-agent:
      apiKeys:
        anthropic:
          value: "sk-ant-your-key-here"
        # Optional: Add more providers
        # openai:
        #   value: "sk-your-key-here"
        # gemini:
        #   value: "your-key-here"
    ```
  </Step>
  
  <Step title="Install TARS">
    ```bash
    helm install tars ./helm \
      --namespace tars \
      --create-namespace \
      -f values.yaml
    ```
  </Step>
  
  <Step title="Access TARS">
    ```bash
    # Port-forward for local access
    kubectl port-forward -n tars svc/tars-ui 9992:9992
    
    # Access at http://localhost:9992
    ```
  </Step>
</Steps>

## Basic Configuration

### API Keys

Configure at least one AI provider:

```yaml
tars-agent:
  apiKeys:
    anthropic:
      value: "sk-ant-your-key-here"
    openai:
      value: "sk-your-key-here"
    gemini:
      value: "your-key-here"
```

### Resource Limits (Optional)

Adjust resources based on your needs:

```yaml
# Desktop container (where automation runs)
desktop:
  resources:
    requests:
      memory: "2Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"

# Agent (AI orchestration)
agent:
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
```

### External Access (Optional)

Enable ingress for domain-based access:

```yaml
ui:
  ingress:
    enabled: true
    hostname: tars.your-domain.com
    tls: true
```

## Accessing TARS

### Local Access (Recommended)

```bash
kubectl port-forward -n tars svc/tars-ui 9992:9992
```

Access at: http://localhost:9992

### External Access

If you configured ingress:
- Access at: https://tars.your-domain.com

## Verifying Deployment

Check that all pods are running:

```bash
kubectl get pods -n tars
```

Expected output:
```
NAME                              READY   STATUS    RESTARTS   AGE
tars-agent-xxxxx               1/1     Running   0          2m
tars-desktop-xxxxx             1/1     Running   0          2m
tars-postgresql-0              1/1     Running   0          2m
tars-ui-xxxxx                 1/1     Running   0          2m
```

## Troubleshooting

### Pods Not Starting

Check pod status:
```bash
kubectl describe pod -n tars <pod-name>
```

Common issues:
- Insufficient memory/CPU: Check node resources with `kubectl top nodes`
- Missing API keys: Verify your values.yaml configuration

### Connection Issues

Test service connectivity:
```bash
kubectl logs -n tars deployment/tars-agent
```

### View Logs

```bash
# All logs
kubectl logs -n tars -l app=tars --tail=100

# Specific component
kubectl logs -n tars deployment/tars-agent
```

## Upgrading

```bash
# Update your values.yaml as needed, then:
helm upgrade tars ./helm -n tars -f values.yaml
```

## Uninstalling

```bash
# Remove TARS
helm uninstall tars -n tars

# Clean up namespace
kubectl delete namespace tars
```

## Advanced Configuration

<AccordionGroup>
  <Accordion title="Using External Secrets">
    If using Kubernetes secret management (Vault, Sealed Secrets, etc.):
    
    ```yaml
    tars-agent:
      apiKeys:
        anthropic:
          useExisting: true
          secretName: "my-api-keys"
          secretKey: "anthropic-key"
    ```
    
    Create the secret manually:
    ```bash
    kubectl create secret generic my-api-keys \
      --namespace tars \
      --from-literal=anthropic-key="sk-ant-your-key"
    ```
  </Accordion>
  
  <Accordion title="LiteLLM Proxy Mode">
    For centralized LLM management, use the included LiteLLM proxy:
    
    ```bash
    helm install tars ./helm \
      -f values-proxy.yaml \
      --namespace tars \
      --create-namespace \
      --set tars-llm-proxy.env.ANTHROPIC_API_KEY="your-key"
    ```
    
    This provides:
    - Centralized API key management
    - Request routing and load balancing
    - Rate limiting and retry logic
  </Accordion>
  
  <Accordion title="Custom Storage">
    Configure persistent storage:
    
    ```yaml
    desktop:
      persistence:
        enabled: true
        size: "20Gi"
        storageClass: "fast-ssd"
    
    postgresql:
      persistence:
        size: "20Gi"
        storageClass: "fast-ssd"
    ```
  </Accordion>
  
  <Accordion title="Production Security">
    ```yaml
    # Network policies
    networkPolicy:
      enabled: true
    
    # Pod security
    podSecurityContext:
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 1000
    
    # Enable authentication
    auth:
      enabled: true
      type: "basic"
      username: "admin"
      password: "changeme"  # Use secrets in production!
    ```
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="API Reference" icon="code" href="/api-reference/introduction">
    Integrate TARS with your applications
  </Card>
  <Card title="LiteLLM Integration" icon="plug" href="/deployment/litellm">
    Use any LLM provider with TARS
  </Card>
</CardGroup>

<Note>
  **Need help?** Join our [Discord community](https://discord.com/invite/d9ewZkWPTP) or check our [GitHub discussions](https://github.com/MagellaX/TARSBOT/discussions).
</Note>